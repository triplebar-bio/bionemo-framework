{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92377fc2",
   "metadata": {},
   "source": [
    "## Parallel Head Data Preprocessing Example\n",
    "\n",
    "### Background and motivation\n",
    "In this notebook, we demonstrate how to preprocess data for training models with multiple prediction heads in parallel using the BioNemo Evo2 framework. This approach allows for efficient handling of diverse biological data types, such as RNA-seq and ChIP-seq, by leveraging parallel processing techniques.\n",
    "\n",
    "For this example, we will focus on preprocessing RNA-seq data from BigWig files and preparing it for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eb1a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace current config.py with modified version for parallel head support, saving a backup of the original.\n",
    "!cp /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/config.py /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/config.py.bak\n",
    "!cp /workspace/sub-packages/bionemo-evo2/src/bionemo/evo2/utils/config.py /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36dc62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from bionemo.core.utils.subprocess_utils import run_subprocess_safely  # noqa\n",
    "\n",
    "\n",
    "data_path = \"parallel_head_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d595929",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEANUP: bool = True\n",
    "if CLEANUP and os.path.exists(data_path):\n",
    "    !rm -rf {data_path}\n",
    "    !rm -rf ./preprocessed_data\n",
    "    !rm parallel_preprocess_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11219043",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_path):\n",
    "    !mkdir -p {data_path}\n",
    "    !wget https://storage.googleapis.com/tbb-public-bucket/datasets/parallel-head-example/GCA_000525045.1_DREv1_genomic.fna -O {data_path}/GCA_000525045.1_DREv1_genomic.fna\n",
    "    !wget https://storage.googleapis.com/tbb-public-bucket/datasets/parallel-head-example/SRR1145649_forward.normalized.bw -O {data_path}/SRR1145649_forward.normalized.bw\n",
    "    !wget https://storage.googleapis.com/tbb-public-bucket/datasets/parallel-head-example/SRR1145649_reverse.normalized.bw -O {data_path}/SRR1145649_reverse.normalized.bw\n",
    "    !wget https://storage.googleapis.com/tbb-public-bucket/datasets/parallel-head-example/GCA_000525045.1_DREv1_genomic.gtf -O {data_path}/GCA_000525045.1_DREv1_genomic.gtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520e1155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a YAML config for preprocessing with RNA-Seq bigwig files.\n",
    "fasta_base = \"GCA_000525045.1_DREv1_genomic.fna\"\n",
    "bigwig_forward = \"SRR1145649_forward.normalized.bw\"  # No need for reverse, since both are handled together.\n",
    "full_fasta_path = os.path.abspath(os.path.join(data_path, fasta_base))\n",
    "output_prefix = \"fungi_dna_rnaseq\"\n",
    "\n",
    "output_dir = os.path.abspath(\"preprocessed_data\")\n",
    "output_yaml = f\"\"\"\n",
    "- datapaths: [\"{full_fasta_path}\"]\n",
    "  output_dir: \"{output_dir}\"\n",
    "  output_prefix: {output_prefix}\n",
    "  train_split: 0.9\n",
    "  valid_split: 0.05\n",
    "  test_split: 0.05\n",
    "  overwrite: True\n",
    "  embed_reverse_complement: true\n",
    "  random_reverse_complement: 0.0\n",
    "  random_lineage_dropout: 0.0\n",
    "  include_sequence_id: false\n",
    "  transcribe: \"back_transcribe\"\n",
    "  force_uppercase: false\n",
    "  indexed_dataset_dtype: \"uint8\"\n",
    "  tokenizer_type: \"Byte-Level\"\n",
    "  vocab_file: null\n",
    "  vocab_size: null\n",
    "  merges_file: null\n",
    "  pretrained_tokenizer_model: null\n",
    "  special_tokens: null\n",
    "  fast_hf_tokenizer: true\n",
    "  append_eod: true\n",
    "  enforce_sample_length: null\n",
    "  ftfy: false\n",
    "  workers: 1\n",
    "  preproc_concurrency: 100000\n",
    "  chunksize: 25\n",
    "  drop_empty_sequences: true\n",
    "  nnn_filter: false  # If you split your fasta on NNN (in human these are contigs), then you should set this to true.\n",
    "  seed: 12342  # Not relevant because we are not using random reverse complement or lineage dropout.\n",
    "  fasta_rnaseq_bigwig_map:\n",
    "    {fasta_base}: {os.path.abspath(os.path.join(data_path, bigwig_forward))}\n",
    "\"\"\"\n",
    "with open(\"parallel_preprocess_config.yaml\", \"w\") as f:\n",
    "    print(output_yaml, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0d74ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can run the preprocessing script with this config.\n",
    "!python \\\n",
    "    /workspace/sub-packages/bionemo-evo2/src/bionemo/evo2/utils/heads/preprocess.py \\\n",
    "    --config parallel_preprocess_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e852ff8",
   "metadata": {},
   "source": [
    "Now that we have a prepared dataset, we can proceed to train our model using the parallel head approach. This involves defining a model architecture that can handle multiple outputs and configuring the training process to optimize for each head simultaneously.\n",
    "\n",
    "We will use the simple dataset we created in the previous section to illustrate this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6be43a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, lets get a model to train\n",
    "if not os.path.exists(\"nemo2_evo2_1b_8k\"):\n",
    "    !evo2_convert_to_nemo2 \\\n",
    "      --model-path hf://arcinstitute/savanna_evo2_1b_base \\\n",
    "      --model-size 1b --output-dir nemo2_evo2_1b_8k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7f7046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the training dataset\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "output_pfx = str(Path(os.path.abspath(\"preprocessed_data\")) / output_prefix)\n",
    "output_yaml = f\"\"\"\n",
    "- dataset_prefix: {output_pfx}_byte-level_train\n",
    "  dataset_split: train\n",
    "  dataset_weight: 1.0\n",
    "- dataset_prefix: {output_pfx}_byte-level_val\n",
    "  dataset_split: validation\n",
    "  dataset_weight: 1.0\n",
    "- dataset_prefix: {output_pfx}_byte-level_test\n",
    "  dataset_split: test\n",
    "  dataset_weight: 1.0\n",
    "\"\"\"\n",
    "with open(\"training_data_config.yaml\", \"w\") as f:\n",
    "    print(output_yaml, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d39109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, lets copy folder /workspace/sub-packages/bionemo-evo2/src/bionemo/evo2/utils/heads to /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/\n",
    "!cp -r \\\n",
    "    /workspace/sub-packages/bionemo-evo2/src/bionemo/evo2/utils/heads \\\n",
    "    /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/\n",
    "\n",
    "# Also copy over loss folder /workspace/sub-packages/bionemo-evo2/src/bionemo/evo2/utils/loss to /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/\n",
    "!cp -r \\\n",
    "    /workspace/sub-packages/bionemo-evo2/src/bionemo/evo2/utils/loss \\\n",
    "    /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a90bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, lets copy folder /workspace/sub-packages/bionemo-evo2/src/bionemo/evo2/utils/heads to /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/\n",
    "!cp -r \\\n",
    "    /workspace/sub-packages/bionemo-evo2/src/bionemo/evo2/utils/heads \\\n",
    "    /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/\n",
    "\n",
    "# Also copy over loss folder /workspace/sub-packages/bionemo-evo2/src/bionemo/evo2/utils/loss to /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/\n",
    "!cp -r \\\n",
    "    /workspace/sub-packages/bionemo-evo2/src/bionemo/evo2/utils/loss \\\n",
    "    /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/\n",
    "\n",
    "# Now lets go ahead and train a model with parallel heads!\n",
    "WARMUP_STEPS = 100\n",
    "\n",
    "# For demo purposes, we use a small number of steps. Still 7 hours on 2 A100/RTX6000 Pro GPUs\n",
    "MAX_STEPS = 1000\n",
    "\n",
    "# Check validation every 25 steps\n",
    "VAL_CHECK_INTERVAL = 25\n",
    "\n",
    "# Use activation checkpointing to save memory\n",
    "MODEL_SUBNET_OPTION = \"--activation-checkpoint-recompute-num-layers 5\"\n",
    "\n",
    "!NCCL_P2P_DISABLE=1 NCCL_IB_DISABLE=1 python \\\n",
    "    /workspace/sub-packages/bionemo-evo2/src/bionemo/evo2/run/train_parallel.py \\\n",
    "    -d training_data_config.yaml \\\n",
    "    --dataset-dir ./preprocessed_data \\\n",
    "    --result-dir parallel_pretraining_demo \\\n",
    "    --experiment-name evo2 \\\n",
    "    --model-size 1b \\\n",
    "    --devices 2 \\\n",
    "    --num-nodes 1 \\\n",
    "    --seq-length 8192 \\\n",
    "    --micro-batch-size 4 \\\n",
    "    --lr 0.000015 \\\n",
    "    --min-lr 0.0000149 \\\n",
    "    --warmup-steps {WARMUP_STEPS} \\\n",
    "    --grad-acc-batches 4 \\\n",
    "    --max-steps {MAX_STEPS} \\\n",
    "    --ckpt-dir nemo2_evo2_1b_8k \\\n",
    "    --clip-grad 5 \\\n",
    "    --wd 0.001 \\\n",
    "    --attention-dropout 0.01 \\\n",
    "    --hidden-dropout 0.01 \\\n",
    "    --val-check-interval {VAL_CHECK_INTERVAL} \\\n",
    "    {MODEL_SUBNET_OPTION} \\\n",
    "    --create-tensorboard-logger \\\n",
    "    --parallel-heads \\\n",
    "    --parallel-dna-head \\\n",
    "    --parallel-rna-seq-head \\\n",
    "    --ckpt-async-save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d5878b",
   "metadata": {},
   "source": [
    "Now that we have a model, lets go ahead and see how well it predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7d34be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you have pyBigWig, gffutils, and Biopython installed in your environment\n",
    "try:\n",
    "    import gffutils\n",
    "    import pyBigWig\n",
    "    from Bio import SeqIO\n",
    "except ImportError:\n",
    "    print(\"Required packages not found. Installing...\")\n",
    "    %pip install pyBigWig gffutils biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13950233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BigWig file parser\n",
    "# GTF file parsing library\n",
    "import gffutils\n",
    "\n",
    "# Import matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pyBigWig\n",
    "\n",
    "# Fasta file parser\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d5a04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_file = \"./parallel_head_data/GCA_000525045.1_DREv1_genomic.fna\"\n",
    "fasta_sequences = SeqIO.to_dict(SeqIO.parse(fasta_file, \"fasta\"))\n",
    "\n",
    "# GTF/GFF directory, select file from metadata\n",
    "gtf_file = \"./parallel_head_data/GCA_000525045.1_DREv1_genomic.gtf\"  # Your GTF/GFF directory here\n",
    "db = gffutils.create_db(\n",
    "    gtf_file,  # GTF/GFF file path here\n",
    "    dbfn=\":memory:\",\n",
    "    force=True,\n",
    "    keep_order=True,\n",
    "    disable_infer_genes=True,\n",
    "    disable_infer_transcripts=True,\n",
    ")\n",
    "\n",
    "# BigWig forward directory, select file from metadata\n",
    "bigwig_forward_file = \"./parallel_head_data/SRR1145649_forward.normalized.bw\"  # Your BigWig directory here\n",
    "bw_forward = pyBigWig.open(bigwig_forward_file)\n",
    "\n",
    "# BigWig reverse directory, select file from metadata\n",
    "bigwig_reverse_file = \"./parallel_head_data/SRR1145649_reverse.normalized.bw\"  # Your BigWig directory here\n",
    "bw_reverse = pyBigWig.open(bigwig_reverse_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1507e764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find first 10 genes in the GTF file that are forward strand since we are looking at a forward strand BigWig\n",
    "genes = list(db.features_of_type(\"transcript\"))\n",
    "genes = [gene for gene in genes if gene.strand == \"+\"]\n",
    "WINDOW_SIZE = 25\n",
    "\n",
    "# Let's plot the coverage for the first `total` genes, we will use this for prediction verification later.\n",
    "total = 1\n",
    "count = 0\n",
    "\n",
    "lower_threshold = 20  # Example threshold for max coverage\n",
    "upper_threshold = 200  # Example upper threshold for max coverage\n",
    "\n",
    "LOGGING: bool = False\n",
    "BUILD_FASTA: bool = True\n",
    "output_fasta = \"./parallel_head_data/example_predict.fna\"\n",
    "\n",
    "# For each gene, find any exons to add as reference points on the plot\n",
    "for gene in genes:\n",
    "    # Define the region to plot (gene +/- WINDOW_SIZE)\n",
    "    start = max(0, gene.start - WINDOW_SIZE)  # type: ignore\n",
    "    end = gene.end + WINDOW_SIZE  # type: ignore\n",
    "\n",
    "    exons = list(db.children(gene, featuretype=\"exon\", order_by=\"start\"))\n",
    "\n",
    "    # Get the coverage data from the BigWig file for the gene region\n",
    "    coverage = bw_forward.values(gene.chrom, start, end, numpy=True)\n",
    "\n",
    "    # Smooth the coverage data using a simple moving average\n",
    "    coverage = pd.Series(coverage).rolling(window=6, min_periods=1, center=True).mean().to_numpy()\n",
    "\n",
    "    max_coverage = coverage.max()\n",
    "\n",
    "    if lower_threshold is not None:\n",
    "        if max_coverage < lower_threshold:\n",
    "            print(\n",
    "                f\"Skipping gene {gene.id} with max coverage {max_coverage} below lower threshold {lower_threshold}\"\n",
    "            ) if LOGGING else None\n",
    "            continue\n",
    "\n",
    "    if upper_threshold is not None:\n",
    "        if max_coverage > upper_threshold:\n",
    "            print(\n",
    "                f\"Skipping gene {gene.id} with max coverage {max_coverage} above upper threshold {upper_threshold}\"\n",
    "            ) if LOGGING else None\n",
    "            continue\n",
    "\n",
    "    print(f\"Processing gene: {gene.id} at {gene.chrom}:{start}-{end}\") if LOGGING else None\n",
    "    if BUILD_FASTA:\n",
    "        # Get the gene sequence from the fasta file\n",
    "        seq_record = fasta_sequences[gene.chrom]\n",
    "        gene_sequence = seq_record.seq[start:end]\n",
    "        # Write to output fasta file\n",
    "        with open(output_fasta, \"a\") as fasta_file:\n",
    "            fasta_file.write(f\">{gene.id}\\n{gene_sequence}\\n\")\n",
    "\n",
    "    # Create x-axis values corresponding to the gene length\n",
    "    x_values = range(start, end)\n",
    "\n",
    "    # Plot the coverage\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(x_values, coverage, label=\"RNA-Seq Coverage\", color=\"blue\")\n",
    "\n",
    "    # Add a horizontal line at 10% of the max coverage to indicate baseline\n",
    "    plt.hlines(\n",
    "        y=max(coverage) * 0.1,\n",
    "        xmin=gene.start,  # type: ignore\n",
    "        xmax=gene.end,  # type: ignore\n",
    "        colors=\"grey\",\n",
    "        linewidth=1,\n",
    "    )\n",
    "\n",
    "    # Add exon reference as small boxes on the plot connected by lines between\n",
    "    for exon in exons:\n",
    "        plt.hlines(\n",
    "            y=max(coverage) * 0.1,\n",
    "            xmin=exon.start,  # type: ignore\n",
    "            xmax=exon.end,  # type: ignore\n",
    "            colors=\"green\",\n",
    "            alpha=0.5,\n",
    "            linewidth=10,\n",
    "            label=\"Exon\" if exon == exons[0] else \"\",\n",
    "        )\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.title(f\"RNA-Seq Coverage for Gene: {gene.id}\")\n",
    "    plt.xlabel(\"Genomic Position\")\n",
    "    plt.ylabel(\"Coverage\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    count += 1\n",
    "    if count >= total:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90213d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, lets copy folder /workspace/sub-packages/bionemo-evo2/src/bionemo/evo2/utils/heads to /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/\n",
    "!cp -r \\\n",
    "    /workspace/sub-packages/bionemo-evo2/src/bionemo/evo2/utils/heads \\\n",
    "    /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/\n",
    "\n",
    "# Also copy over loss folder /workspace/sub-packages/bionemo-evo2/src/bionemo/evo2/utils/loss to /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/\n",
    "!cp -r \\\n",
    "    /workspace/sub-packages/bionemo-evo2/src/bionemo/evo2/utils/loss \\\n",
    "    /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/\n",
    "\n",
    "# Now that we have a fasta file for prediction, we can run inference with our trained model!\n",
    "INPUT_FASTA = os.path.abspath(\"./parallel_head_data/example_predict.fna\")\n",
    "CKPT_DIR = os.path.abspath(\n",
    "    \"./parallel_pretraining_demo/evo2/checkpoints/epoch=0-step=999-consumed_samples=32000.0-last\"\n",
    ")\n",
    "OUTPUT_DIR = os.path.abspath(\"./parallel_head_data/predictions\")\n",
    "\n",
    "!python \\\n",
    "    /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/heads/predict.py \\\n",
    "    --fasta {INPUT_FASTA} \\\n",
    "    --ckpt-dir {CKPT_DIR} \\\n",
    "    --output-dir {OUTPUT_DIR} \\\n",
    "    --model-size 1b \\\n",
    "    --parallel-heads \\\n",
    "    --parallel-dna-head \\\n",
    "    --parallel-rna-seq-head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78746445",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEANUP: bool = True\n",
    "if CLEANUP and os.path.exists(data_path):\n",
    "    !rm -rf {data_path}\n",
    "    !rm -rf parallel_pretraining_demo\n",
    "    !rm -rf preprocessed_data\n",
    "    !rm parallel_preprocess_config.yaml\n",
    "    !mv /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/config.py.bak /usr/local/lib/python3.12/dist-packages/bionemo/evo2/utils/config.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
